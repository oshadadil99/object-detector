{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c51d5df3-acdf-4786-a0e5-754215a4a335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import pathlib\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cde6847a-c0fa-443a-af5a-12349020ac54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89ea9e22-0b3b-4520-8195-56c72fbd8c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# patch tf1 into `utils.ops`\n",
    "utils_ops.tf = tf.compat.v1\n",
    "\n",
    "# Patch the location of gfile\n",
    "tf.gfile = tf.io.gfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e568ab48-5f5b-462f-bce2-0c4de80939f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name):\n",
    "  base_url = 'http://download.tensorflow.org/models/object_detection/'\n",
    "  model_file = model_name + '.tar.gz'\n",
    "  model_dir = tf.keras.utils.get_file(\n",
    "    fname=model_name, \n",
    "    origin=base_url + model_file,\n",
    "    untar=True)\n",
    "\n",
    "  model_dir = pathlib.Path(model_dir)/\"saved_model\"\n",
    "\n",
    "  model = tf.saved_model.load(str(model_dir))\n",
    "  model = model.signatures['serving_default']\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf41cdd3-4a56-4078-90f1-d7e35490159c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_LABELS = 'object_detection/data/mscoco_label_map.pbtxt'\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a02e3f6e-1525-4712-a068-0e384fd98110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('object_detection/test_images/image1.jpg'),\n",
       " WindowsPath('object_detection/test_images/image2.jpg'),\n",
       " WindowsPath('object_detection/test_images/image3.jpg')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_TO_TEST_IMAGES_DIR = pathlib.Path('object_detection/test_images')\n",
    "TEST_IMAGE_PATHS = sorted(list(PATH_TO_TEST_IMAGES_DIR.glob(\"*.jpg\")))\n",
    "TEST_IMAGE_PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4642d07e-1d58-451d-9268-0118255e6f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_2017_11_17.tar.gz\n",
      "76534733/76534733 [==============================] - 9s 0us/step\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "model_name = 'ssd_mobilenet_v1_coco_2017_11_17'\n",
    "detection_model = load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56502d76-da8b-4f55-a579-cea84d1ad31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'image_tensor:0' shape=(None, None, None, 3) dtype=uint8>]\n"
     ]
    }
   ],
   "source": [
    "print(detection_model.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9514589-051a-481b-a5cf-14cfeae5f843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'detection_classes': tf.float32,\n",
       " 'detection_boxes': tf.float32,\n",
       " 'num_detections': tf.float32,\n",
       " 'detection_scores': tf.float32}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection_model.output_dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1e613b8-ffcb-463a-92f9-d4212f892b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'detection_classes': TensorShape([None, 100]),\n",
       " 'detection_boxes': TensorShape([None, 100, 4]),\n",
       " 'num_detections': TensorShape([None]),\n",
       " 'detection_scores': TensorShape([None, 100])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection_model.output_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8132ff92-20f7-4dce-8b5d-43a59cafff51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_for_single_image(model, image):\n",
    "  image = np.asarray(image)\n",
    "  input_tensor = tf.convert_to_tensor(image)\n",
    "  input_tensor = input_tensor[tf.newaxis,...]\n",
    "\n",
    "  output_dict = model(input_tensor)\n",
    "    \n",
    "  num_detections = int(output_dict.pop('num_detections'))\n",
    "  output_dict = {key:value[0, :num_detections].numpy() \n",
    "                 for key,value in output_dict.items()}\n",
    "  output_dict['num_detections'] = num_detections\n",
    "\n",
    "  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
    "   \n",
    "  if 'detection_masks' in output_dict:\n",
    "    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "              output_dict['detection_masks'], output_dict['detection_boxes'],\n",
    "               image.shape[0], image.shape[1])      \n",
    "    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n",
    "                                       tf.uint8)\n",
    "    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
    "    \n",
    "  return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de773500-abfa-417e-8e82-31dff452d37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_inference(model, image_path):\n",
    "\n",
    "  image_np = np.array(Image.open(image_path))\n",
    "  output_dict = run_inference_for_single_image(model, image_np)\n",
    "  vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "      image_np,\n",
    "      output_dict['detection_boxes'],\n",
    "      output_dict['detection_classes'],\n",
    "      output_dict['detection_scores'],\n",
    "      category_index,\n",
    "      instance_masks=output_dict.get('detection_masks_reframed', None),\n",
    "      use_normalized_coordinates=True,\n",
    "      line_thickness=8)\n",
    "\n",
    "  display(Image.fromarray(image_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f29c529-5b13-4cee-91b1-8d7f12ef62d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_path in TEST_IMAGE_PATHS:\n",
    "  show_inference(detection_model, image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c49cca1-128b-4228-a83b-8cd38f505bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
